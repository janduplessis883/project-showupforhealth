{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab68b25",
   "metadata": {
    "id": "f959fee9-5b7d-4202-90f9-1cc2f8641523"
   },
   "source": [
    "<div class='alert' style='background-color: #273333; color: #E5E7E8; padding:26px 26px; border-radius:15px; font-size:40px;'><B>Show Up </B> for Health - Deep Learning + No Shows</div><span style='color: #273333; padding:26px 26px; font-size:11px;'> Powered by <B>AutoNote </B>and<b> üçè ShowUp </b>helper class</B></span><div style='margin:4px 26px; color:#273333; font-size:17px;'>\n",
    "<ol>\n",
    "<li><B>Problem statement</B>: A clear description of the problem the project aims to solve.</li><BR>\n",
    "<li><B>Data source</B>: Information on where the data used in the project is obtained from.</li><BR>\n",
    "<li><B>Libraries used</B>: A list of the Python libraries used in the project and a brief explanation of their role. Include library version.</li><BR>\n",
    "<li><B>Exploratory Data Analysis (EDA)</B>: A summary of the initial findings from exploring the data.</li><BR>\n",
    "<li><B>Preprocessing</B>: Steps taken to clean and prepare the data for model building.</li><BR>\n",
    "<li><B>Model building</B>: An overview of the model used and the reasoning behind its selection.</li><BR>\n",
    " Precision = $\\frac{\\text{true positives}}{\\text{true positives + false positives}}$, Recall = $\\frac{\\text{true positives}}{\\text{true positives + false negatives}}$, F1 = $2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision + recall}}$</li><BR><BR>\n",
    "<li><B>Model evaluation</B>: Evaluation metrics used to assess the performance of the model and results of the evaluation.</li><BR>\n",
    "<li><B>Conclusion</B>: A summary of the findings and recommendations for further work.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb401c6",
   "metadata": {},
   "source": [
    "#  üçè Loading Helper Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9456eb",
   "metadata": {},
   "source": [
    "wandb_api_key: 651204c459ad2877b0d32ae2f37ce28d159a9cbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3affb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrjanduplessis\u001b[0m (\u001b[33mbromptonhealthpcn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8220a5",
   "metadata": {
    "id": "12b2f75b-edda-4234-b447-49994b01e550"
   },
   "outputs": [],
   "source": [
    "# Importing default Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "# Hi-resolution Plots and Matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the maximum number of rows and columns to be displayed\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# \"magic commands\" to enable autoreload of your imported packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a683b6",
   "metadata": {},
   "source": [
    "# üìô Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98b1c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:08:04.898909Z",
     "start_time": "2023-07-31T06:08:00.658415Z"
    },
    "id": "d069592d-5175-4382-a060-3c9b8edd9e90"
   },
   "outputs": [],
   "source": [
    "''' Scikit-Learn'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "''' Imbalanced Classes'''\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "''' Tensorflow Keras'''\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from showupforhealth.params import *\n",
    "from showupforhealth.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ca65d",
   "metadata": {},
   "source": [
    "# üíæ Build Surgery Datasets\n",
    "Merge **Appointment Data** with **Surgery Disease Register**, Weather and IMD2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "008ae71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901516, 37)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'{OUTPUT_DATA}full_train_data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9d0b4",
   "metadata": {},
   "source": [
    "## üöß Under sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed7ede48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def undersample_majority(df, target_col, undersample_factor):\n",
    "\n",
    "    # Separate majority and minority classes\n",
    "    df_majority = df[df[target_col]==0] \n",
    "    df_minority = df[df[target_col]==1]\n",
    "\n",
    "    # Undersample majority by factor\n",
    "    n_samples = len(df_minority) * undersample_factor\n",
    "    df_majority_under = resample(df_majority, replace=False, n_samples=n_samples, random_state=123)\n",
    "\n",
    "    # Combine minority class with undersampled majority class\n",
    "    df_undersampled = pd.concat([df_majority_under, df_minority])\n",
    "\n",
    "    # Shuffle rows\n",
    "    df_undersampled = df_undersampled.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    return df_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0e938b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot sample 2601396 out of arrays with dim 34384 when replace is False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_under \u001b[38;5;241m=\u001b[39m \u001b[43mundersample_majority\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAppointment_status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mundersample_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m, in \u001b[0;36mundersample_majority\u001b[0;34m(df, target_col, undersample_factor)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Undersample majority by factor\u001b[39;00m\n\u001b[1;32m     10\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_minority) \u001b[38;5;241m*\u001b[39m undersample_factor\n\u001b[0;32m---> 11\u001b[0m df_majority_under \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_majority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Combine minority class with undersampled majority class\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_undersampled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_majority_under, df_minority])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/showupforhealth/lib/python3.10/site-packages/sklearn/utils/__init__.py:564\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(replace, n_samples, random_state, stratify, *arrays)\u001b[0m\n\u001b[1;32m    562\u001b[0m     max_n_samples \u001b[38;5;241m=\u001b[39m n_samples\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (max_n_samples \u001b[38;5;241m>\u001b[39m n_samples) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m replace):\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot sample \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m out of arrays with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m when replace is False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;241m%\u001b[39m (max_n_samples, n_samples)\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    569\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot sample 2601396 out of arrays with dim 34384 when replace is False"
     ]
    }
   ],
   "source": [
    "df_under = undersample_majority(data, 'Appointment_status', undersample_factor=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8989e",
   "metadata": {},
   "source": [
    "## Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1154d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:08:45.125638Z",
     "start_time": "2023-07-31T06:08:45.030851Z"
    },
    "id": "f3657b11-7627-41c0-91aa-4df38de39567"
   },
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X, y = define_X_y(data, 'Appointment_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167ba7c",
   "metadata": {},
   "source": [
    "# ‚úÇÔ∏è Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f4dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:09:42.311289Z",
     "start_time": "2023-07-31T06:09:42.174171Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, val_size=0.3, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfa281",
   "metadata": {},
   "source": [
    "# ‚öñÔ∏è Class imbalance\n",
    "Including **distribution of imbalance** within train, val and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db17c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:09:48.168104Z",
     "start_time": "2023-07-31T06:09:48.070769Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many \"fraud\" samples do I have in each split?\n",
    "print(\"DNA distribution in train val and test set pre-oversampling\")\n",
    "print(\"-\"*75)\n",
    "print(f\"There are {pd.Series(y_train).value_counts()[0]} DNAs in the train set\")\n",
    "print(f\"There are {pd.Series(y_val).value_counts()[0]} DNAs in the val set\")\n",
    "print(f\"There are {pd.Series(y_test).value_counts()[0]} DNAs in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad181f",
   "metadata": {},
   "source": [
    "# üîÅ Oversampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288e88f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:10:04.783204Z",
     "start_time": "2023-07-31T06:10:04.575261Z"
    },
    "id": "f3657b11-7627-41c0-91aa-4df38de39567"
   },
   "outputs": [],
   "source": [
    "# Oversampling with SMOTE\n",
    "X_train_os, y_train_os = oversample_with_smote(X_train, y_train, sampling_strategy=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72490f5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:10:05.097863Z",
     "start_time": "2023-07-31T06:10:05.034819Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many \"fraud\" samples do I have in each split?\n",
    "print(\"DNAs in X_train_o post-oversampling\")\n",
    "print(\"-\"*75)\n",
    "print(f\"There are {pd.Series(y_train_o).value_counts()[0]} DNAs in the train set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c6f0fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T03:55:13.815466Z",
     "start_time": "2023-07-31T03:55:13.744023Z"
    },
    "id": "f3657b11-7627-41c0-91aa-4df38de39567"
   },
   "outputs": [],
   "source": [
    "#Scale data\n",
    "# Fit the scaler on the training data\n",
    "scaler = fit_scaler(X_train_os, scaler_type='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60478e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T03:55:13.815466Z",
     "start_time": "2023-07-31T03:55:13.744023Z"
    },
    "id": "f3657b11-7627-41c0-91aa-4df38de39567"
   },
   "outputs": [],
   "source": [
    "# Use the fitted scaler to transform both training and test datasets\n",
    "X_train_scaled = transform_data(X_train_os, scaler)\n",
    "X_val_scaled = transform_data(X_val, scaler)\n",
    "X_test_scaled = transform_data(X_test, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4c585",
   "metadata": {},
   "source": [
    "# üß† Neural Network iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752766e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:10:55.636444Z",
     "start_time": "2023-07-31T06:10:55.508539Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred): # defining a custom F1 score metric\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "    f1_score,  # adding the custom F1 score metric\n",
    "#     keras.metrics.TruePositives(name='tp'),\n",
    "#     keras.metrics.FalsePositives(name='fp'),\n",
    "#     keras.metrics.TrueNegatives(name='tn'),\n",
    "#     keras.metrics.FalseNegatives(name='fn'), \n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88334823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:34:59.474023Z",
     "start_time": "2023-07-31T06:34:59.407063Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_loss_precision_recall_curve(history):\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(20, 15))\n",
    "\n",
    "    # --- LOSS \n",
    "    ax[0, 0].plot(history.history['loss'], color=\"#a10606\")\n",
    "    ax[0, 0].plot(history.history['val_loss'], color=\"#1b5743\")\n",
    "    ax[0, 0].set_title('Model loss', fontsize = 18)\n",
    "    ax[0, 0].set_ylabel('Loss', fontsize = 14)\n",
    "    ax[0, 0].legend(['Train', 'Val'], loc='upper right')\n",
    "    ax[0, 0].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[0, 0].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "    # --- RECALL\n",
    "    ax[0, 1].plot(history.history['recall']) \n",
    "    ax[0, 1].plot(history.history['val_recall'])\n",
    "    ax[0, 1].set_title('Model recall', fontsize = 18)\n",
    "    ax[0, 1].set_ylabel('Recall', fontsize = 14) \n",
    "    ax[0, 1].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[0, 1].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[0, 1].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "    # --- PRECISION\n",
    "    ax[1, 0].plot(history.history['precision'])\n",
    "    ax[1, 0].plot(history.history['val_precision'])\n",
    "    ax[1, 0].set_title('Model precision', fontsize = 18)\n",
    "    ax[1, 0].set_ylabel('Precision', fontsize = 14)\n",
    "    ax[1, 0].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[1, 0].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[1, 0].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "    # --- F1 SCORE \n",
    "    ax[1, 1].plot(history.history['f1_score'])\n",
    "    ax[1, 1].plot(history.history['val_f1_score']) \n",
    "    ax[1, 1].set_title('Model F1 Score', fontsize = 18)\n",
    "    ax[1, 1].set_ylabel('F1 Score', fontsize = 14)\n",
    "    ax[1, 1].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[1, 1].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[1, 1].grid(axis=\"y\", linewidth=0.5)\n",
    "    \n",
    "    # --- AUC\n",
    "    ax[2, 0].plot(history.history['auc'])\n",
    "    ax[2, 0].plot(history.history['val_auc'])\n",
    "    ax[2, 0].set_title('Model AUC', fontsize = 18) \n",
    "    ax[2, 0].set_ylabel('AUC', fontsize = 14)\n",
    "    ax[2, 0].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[2, 0].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[2, 0].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "\n",
    "    ax[2, 1].plot(history.history['accuracy'])\n",
    "    ax[2, 1].plot(history.history['val_accuracy'])\n",
    "    ax[2, 1].set_title('Model accuracy', fontsize = 18) \n",
    "    ax[2, 1].set_ylabel('accuracy', fontsize = 14)\n",
    "    ax[2, 1].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[2, 1].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[2, 1].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "    # Set common labels  \n",
    "    fig.text(0.5, 0.04, 'Epoch', ha='center', va='center', fontsize=14) \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d80f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "# Start a run, tracking hyperparameters\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"ShowUp NEW DATA\",\n",
    "\n",
    "    # track hyperparameters and run metadata with wandb.config\n",
    "    config={\n",
    "        \"layer_1\": 256,\n",
    "        \"activation_1\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.3, 0.8),\n",
    "        \"layer_2\": 16,\n",
    "        \"activation_2\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.3, 0.8),\n",
    "        \"layer_3\": 32,\n",
    "        \"activation_3\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.3, 0.8),\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"epoch\": 200,\n",
    "        \"batch_size\": 128\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ea975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T07:06:14.743121Z",
     "start_time": "2023-07-31T07:06:14.604175Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def init_model():\n",
    "\n",
    "    # Assuming X_train_o_s is globally accessible; otherwise, pass it as a parameter.\n",
    "    # Only take the dimensions of a single sample, excluding the batch size.\n",
    "    input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Input layer specifying the shape\n",
    "    model.add(layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "#     model.add(layers.Dense(512, activation='relu'))\n",
    "#     #model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.3))\n",
    "\n",
    "#     model.add(layers.Dense(256, activation='relu'))\n",
    "#     #model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=1e-4)\n",
    "    \n",
    "    # Assuming 'metrics' is defined globally; otherwise, specify it directly or pass it as a parameter.\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042be68a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T07:06:17.931535Z",
     "start_time": "2023-07-31T07:06:16.838275Z"
    }
   },
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201ea69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T07:06:38.133672Z",
     "start_time": "2023-07-31T07:06:17.932703Z"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    patience=80,\n",
    "    monitor='val_recall', # We really want to detect fraudulent transactions!\n",
    "    restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train_os,\n",
    "                    validation_data=(X_val_scaled, y_val),\n",
    "                    epochs=200,\n",
    "                    batch_size=128, # Large enough to get a decent chance of containing fraudulent transactions \n",
    "                    callbacks=[es,\n",
    "                      WandbMetricsLogger(log_freq=5),\n",
    "                      WandbModelCheckpoint(\"models\")], \n",
    "                    shuffle=True,\n",
    "                    verbose=3\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18051cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T07:06:38.797653Z",
     "start_time": "2023-07-31T07:06:38.136164Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_precision_recall_curve(history)\n",
    "print(\"Show Up for Health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319072db",
   "metadata": {},
   "source": [
    "# Score model on unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ce418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:43:31.716520Z",
     "start_time": "2023-07-31T06:43:29.929511Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0e42c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:43:36.488663Z",
     "start_time": "2023-07-31T06:43:35.792344Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test, verbose=0, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7da8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "datetime_string = now.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "model.save(f'model_weights_{datetime_string}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09994d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:43:54.615057Z",
     "start_time": "2023-07-31T06:43:53.912913Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576adafc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:02.554092Z",
     "start_time": "2023-07-31T06:44:02.464459Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.50 # 50% \n",
    "\n",
    "y_pred_binary = np.where(y_pred_proba > threshold, 1, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96876d",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786ff08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:06.263268Z",
     "start_time": "2023-07-31T06:44:06.160737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test,y_pred_binary)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebe0c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:08.332607Z",
     "start_time": "2023-07-31T06:44:08.137717Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d8189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:33.862657Z",
     "start_time": "2023-07-31T06:44:33.712813Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d1b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:35.437489Z",
     "start_time": "2023-07-31T06:44:35.356271Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = precision_recall_curve(labels, predictions)\n",
    "    plt.plot(recall, precision, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c01fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:36.687973Z",
     "start_time": "2023-07-31T06:44:36.527403Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_prc(\"Test\", y_test, y_pred_proba, linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50b547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17f082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
