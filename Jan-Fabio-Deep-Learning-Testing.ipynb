{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab68b25",
   "metadata": {
    "id": "f959fee9-5b7d-4202-90f9-1cc2f8641523"
   },
   "source": [
    "<div class='alert' style='background-color: #273333; color: #E5E7E8; padding:26px 26px; border-radius:15px; font-size:40px;'><B>Show Up </B> for Health - Deep Learning + No Shows</div><span style='color: #273333; padding:26px 26px; font-size:11px;'> Powered by <B>AutoNote </B>and<b> üçè ShowUp </b>helper class</B></span><div style='margin:4px 26px; color:#273333; font-size:17px;'>\n",
    "<ol>\n",
    "<li><B>Problem statement</B>: A clear description of the problem the project aims to solve.</li><BR>\n",
    "<li><B>Data source</B>: Information on where the data used in the project is obtained from.</li><BR>\n",
    "<li><B>Libraries used</B>: A list of the Python libraries used in the project and a brief explanation of their role. Include library version.</li><BR>\n",
    "<li><B>Exploratory Data Analysis (EDA)</B>: A summary of the initial findings from exploring the data.</li><BR>\n",
    "<li><B>Preprocessing</B>: Steps taken to clean and prepare the data for model building.</li><BR>\n",
    "<li><B>Model building</B>: An overview of the model used and the reasoning behind its selection.</li><BR>\n",
    " Precision = $\\frac{\\text{true positives}}{\\text{true positives + false positives}}$, Recall = $\\frac{\\text{true positives}}{\\text{true positives + false negatives}}$, F1 = $2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision + recall}}$</li><BR><BR>\n",
    "<li><B>Model evaluation</B>: Evaluation metrics used to assess the performance of the model and results of the evaluation.</li><BR>\n",
    "<li><B>Conclusion</B>: A summary of the findings and recommendations for further work.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb401c6",
   "metadata": {},
   "source": [
    "#  üçè Loading Helper Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9456eb",
   "metadata": {},
   "source": [
    "wandb_api_key: 651204c459ad2877b0d32ae2f37ce28d159a9cbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3affb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdrjanduplessis\u001b[0m (\u001b[33mbromptonhealthpcn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8220a5",
   "metadata": {
    "id": "12b2f75b-edda-4234-b447-49994b01e550"
   },
   "outputs": [],
   "source": [
    "# Importing default Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "# Hi-resolution Plots and Matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the maximum number of rows and columns to be displayed\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# \"magic commands\" to enable autoreload of your imported packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a683b6",
   "metadata": {},
   "source": [
    "# üìô Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98b1c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:08:04.898909Z",
     "start_time": "2023-07-31T06:08:00.658415Z"
    },
    "id": "d069592d-5175-4382-a060-3c9b8edd9e90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 17:42:25.616441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "''' Scikit-Learn'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "''' Imbalanced Classes'''\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "''' Tensorflow Keras'''\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from showupforhealth.params import *\n",
    "from showupforhealth.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ca65d",
   "metadata": {},
   "source": [
    "# üíæ Build Surgery Datasets\n",
    "Merge **Appointment Data** with **Surgery Disease Register**, Weather and IMD2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ce9098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appointment_status</th>\n",
       "      <th>temp</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>FRAILTY</th>\n",
       "      <th>DEPRESSION</th>\n",
       "      <th>OBESITY</th>\n",
       "      <th>IHD</th>\n",
       "      <th>DM</th>\n",
       "      <th>HPT</th>\n",
       "      <th>NDHG</th>\n",
       "      <th>SMI</th>\n",
       "      <th>IMD2023</th>\n",
       "      <th>dist_to_station</th>\n",
       "      <th>distance_to_surg</th>\n",
       "      <th>book_to_app_days</th>\n",
       "      <th>booked_by_clinician</th>\n",
       "      <th>registered_for_months</th>\n",
       "      <th>sin_week</th>\n",
       "      <th>cos_week</th>\n",
       "      <th>sin_Appointment_time</th>\n",
       "      <th>cos_Appointment_time</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>cos_month</th>\n",
       "      <th>sin_day_of_week</th>\n",
       "      <th>cos_day_of_week</th>\n",
       "      <th>No_shows</th>\n",
       "      <th>Rota_ARRS</th>\n",
       "      <th>Rota_GP</th>\n",
       "      <th>Rota_HCA</th>\n",
       "      <th>Rota_Nurse</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Mixed</th>\n",
       "      <th>Ethnicity_Other</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22698.0</td>\n",
       "      <td>0.519419</td>\n",
       "      <td>0.816996</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10169.0</td>\n",
       "      <td>0.540792</td>\n",
       "      <td>1.656309</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10169.0</td>\n",
       "      <td>0.540792</td>\n",
       "      <td>1.656309</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8243.0</td>\n",
       "      <td>0.332691</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7626.0</td>\n",
       "      <td>0.155802</td>\n",
       "      <td>0.215224</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Appointment_status  temp  precipitation  Age  Sex  FRAILTY  DEPRESSION  \\\n",
       "0                   1  17.7            0.0   40    0     0.00           0   \n",
       "1                   1  18.5            0.0   70    2     0.39           0   \n",
       "2                   1  18.5            0.0   70    2     0.39           0   \n",
       "3                   1  19.4            0.0   66    2     0.03           1   \n",
       "4                   1  18.3            0.0   58    0     0.11           0   \n",
       "\n",
       "   OBESITY  IHD  DM  HPT  NDHG  SMI  IMD2023  dist_to_station  \\\n",
       "0        0    0   0    0     0    0  22698.0         0.519419   \n",
       "1        1    0   1    1     0    0  10169.0         0.540792   \n",
       "2        1    0   1    1     0    0  10169.0         0.540792   \n",
       "3        0    0   0    1     0    0   8243.0         0.332691   \n",
       "4        1    0   0    0     0    0   7626.0         0.155802   \n",
       "\n",
       "   distance_to_surg  book_to_app_days  booked_by_clinician  \\\n",
       "0          0.816996              54.0                    1   \n",
       "1          1.656309              49.0                    0   \n",
       "2          1.656309              49.0                    0   \n",
       "3          0.600495              37.0                    0   \n",
       "4          0.215224              27.0                    0   \n",
       "\n",
       "   registered_for_months  sin_week  cos_week  sin_Appointment_time  \\\n",
       "0                   17.0 -0.120537 -0.992709              0.707107   \n",
       "1                   12.0 -0.120537 -0.992709              0.500000   \n",
       "2                   12.0 -0.120537 -0.992709              0.500000   \n",
       "3                   70.0 -0.120537 -0.992709              0.258819   \n",
       "4                   28.0 -0.120537 -0.992709              0.707107   \n",
       "\n",
       "   cos_Appointment_time  sin_month  cos_month  sin_day_of_week  \\\n",
       "0             -0.707107       -0.5  -0.866025         0.781831   \n",
       "1             -0.866025       -0.5  -0.866025         0.781831   \n",
       "2             -0.866025       -0.5  -0.866025         0.781831   \n",
       "3             -0.965926       -0.5  -0.866025         0.433884   \n",
       "4             -0.707107       -0.5  -0.866025         0.433884   \n",
       "\n",
       "   cos_day_of_week  No_shows  Rota_ARRS  Rota_GP  Rota_HCA  Rota_Nurse  \\\n",
       "0         0.623490       2.0        0.0      0.0       0.0         1.0   \n",
       "1         0.623490       2.0        0.0      0.0       0.0         1.0   \n",
       "2         0.623490       2.0        0.0      0.0       0.0         1.0   \n",
       "3        -0.900969      10.0        0.0      0.0       1.0         0.0   \n",
       "4        -0.900969       0.0        0.0      0.0       0.0         1.0   \n",
       "\n",
       "   Ethnicity_Asian  Ethnicity_Black  Ethnicity_Mixed  Ethnicity_Other  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              1.0              0.0              0.0              0.0   \n",
       "2              1.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   Ethnicity_White  \n",
       "0              1.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              1.0  \n",
       "4              1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'{OUTPUT_DATA}full_train_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8989e",
   "metadata": {},
   "source": [
    "## Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1154d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:08:45.125638Z",
     "start_time": "2023-07-31T06:08:45.030851Z"
    },
    "id": "f3657b11-7627-41c0-91aa-4df38de39567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X - independant variable shape: (901516, 36)\n",
      "y - dependant variable - Appointment_status: (901516,)\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X, y = define_X_y(data, 'Appointment_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167ba7c",
   "metadata": {},
   "source": [
    "# ‚úÇÔ∏è Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830f4dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:09:42.311289Z",
     "start_time": "2023-07-31T06:09:42.174171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OUTPUT: X_train, X_val, X_test, y_train, y_val, y_test\n",
      "Train Set:  X_train, y_train - (631060, 36), (631060,)\n",
      "  Val Set:  X_val, y_val - - - (180304, 36), (180304,)\n",
      " Test Set:  X_test, y_test - - (90152, 36), (90152,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, val_size=0.2, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfa281",
   "metadata": {},
   "source": [
    "# ‚öñÔ∏è Class imbalance\n",
    "Including **distribution of imbalance** within train, val and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4db17c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:09:48.168104Z",
     "start_time": "2023-07-31T06:09:48.070769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA distribution in train val and test set pre-oversampling\n",
      "---------------------------------------------------------------------------\n",
      "There are 24036 DNAs in the train set\n",
      "There are 6816 DNAs in the val set\n",
      "There are 3532 DNAs in the test set\n"
     ]
    }
   ],
   "source": [
    "# How many \"fraud\" samples do I have in each split?\n",
    "print(\"DNA distribution in train val and test set pre-oversampling\")\n",
    "print(\"-\"*75)\n",
    "print(f\"There are {pd.Series(y_train).value_counts()[0]} DNAs in the train set\")\n",
    "print(f\"There are {pd.Series(y_val).value_counts()[0]} DNAs in the val set\")\n",
    "print(f\"There are {pd.Series(y_test).value_counts()[0]} DNAs in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad181f",
   "metadata": {},
   "source": [
    "# üîÅ Oversampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a288e88f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:10:04.783204Z",
     "start_time": "2023-07-31T06:10:04.575261Z"
    },
    "id": "f3657b11-7627-41c0-91aa-4df38de39567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Oversampled: SMOTE - X_train_os:(667726, 36) y_train_os :(667726,)\n"
     ]
    }
   ],
   "source": [
    "# Oversampling with SMOTE\n",
    "X_train_o, y_train_o = oversample_with_smote(X_train, y_train, sampling_strategy=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72490f5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:10:05.097863Z",
     "start_time": "2023-07-31T06:10:05.034819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNAs in X_train_o post-oversampling\n",
      "---------------------------------------------------------------------------\n",
      "There are 60702 DNAs in the train set\n"
     ]
    }
   ],
   "source": [
    "# How many \"fraud\" samples do I have in each split?\n",
    "print(\"DNAs in X_train_o post-oversampling\")\n",
    "print(\"-\"*75)\n",
    "print(f\"There are {pd.Series(y_train_o).value_counts()[0]} DNAs in the train set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba73e7",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c38a8f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 17:42:42.500633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x149629060>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "# Create the denoising autoencoder\n",
    "def create_denoising_autoencoder(input_dim, encoding_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    noisy_input = GaussianNoise(0.5)(input_layer)  # Add Gaussian noise to input\n",
    "    encoded = Dense(encoding_dim, activation='relu')(noisy_input)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "input_dim = 36  # Adjust this to match your input dimension\n",
    "encoding_dim = 128  # Adjust this to set the encoding dimension (autoencoder = )\n",
    "create_denoising_autoencoder(input_dim, encoding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f45fcc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_scaler(df, scaler_type='minmax'):\n",
    "    \"\"\"\n",
    "    Fit the scaler on the given data.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The dataframe on which the scaler is to be fitted.\n",
    "        scaler_type (str, optional): The type of scaling method to use. Can be 'standard', 'minmax', or 'robust'. Default is 'minmax'.\n",
    "\n",
    "    Returns:\n",
    "        scaler_instance: Fitted scaler.\n",
    "    \"\"\"\n",
    "    if scaler_type == 'standard':\n",
    "        scaler_instance = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler_instance = MinMaxScaler()\n",
    "    elif scaler_type == 'robust':\n",
    "        scaler_instance = RobustScaler()\n",
    "    else:\n",
    "        raise ValueError('Invalid scaler type. Choose \"standard\", \"minmax\", or \"robust\".')\n",
    "\n",
    "    scaler_instance.fit(df)\n",
    "    \n",
    "    return scaler_instance\n",
    "\n",
    "def transform_data(df, scaler_instance):\n",
    "    \"\"\"\n",
    "    Transform the given data using the provided scaler.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The dataframe to transform.\n",
    "        scaler_instance: The scaler instance to use for transformation.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Transformed data.\n",
    "    \"\"\"\n",
    "    column_headers = df.columns\n",
    "    scaled_values = scaler_instance.transform(df)\n",
    "    scaled_df = pd.DataFrame(scaled_values, columns=column_headers)\n",
    "\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab45be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T03:55:13.815466Z",
     "start_time": "2023-07-31T03:55:13.744023Z"
    },
    "id": "f3657b11-7627-41c0-91aa-4df38de39567"
   },
   "outputs": [],
   "source": [
    "#Scale data\n",
    "# Fit the scaler on the training data\n",
    "scaler = fit_scaler(X_train_o, scaler_type='minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb60478e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T03:55:13.815466Z",
     "start_time": "2023-07-31T03:55:13.744023Z"
    },
    "id": "f3657b11-7627-41c0-91aa-4df38de39567"
   },
   "outputs": [],
   "source": [
    "# Use the fitted scaler to transform both training and test datasets\n",
    "X_train_scaled = transform_data(X_train_o, scaler)\n",
    "X_val_scaled = transform_data(X_val, scaler)\n",
    "X_test_scaled = transform_data(X_test, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4c585",
   "metadata": {},
   "source": [
    "# üß† Neural Network iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5752766e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:10:55.636444Z",
     "start_time": "2023-07-31T06:10:55.508539Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred): # defining a custom F1 score metric\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "   f1_score,  # adding the custom F1 score metric\n",
    "#     keras.metrics.TruePositives(name='tp'),\n",
    "#     keras.metrics.FalsePositives(name='fp'),\n",
    "#     keras.metrics.TrueNegatives(name='tn'),\n",
    "#     keras.metrics.FalseNegatives(name='fn'), \n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88334823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:34:59.474023Z",
     "start_time": "2023-07-31T06:34:59.407063Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_loss_precision_recall_curve(history):\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(20, 15))\n",
    "\n",
    "    # --- LOSS \n",
    "    ax[0, 0].plot(history.history['loss'], color=\"#a10606\")\n",
    "    ax[0, 0].plot(history.history['val_loss'], color=\"#1b5743\")\n",
    "    ax[0, 0].set_title('Model loss', fontsize = 18)\n",
    "    ax[0, 0].set_ylabel('Loss', fontsize = 14)\n",
    "    ax[0, 0].legend(['Train', 'Val'], loc='upper right')\n",
    "    ax[0, 0].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[0, 0].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "    # --- RECALL\n",
    "    ax[0, 1].plot(history.history['recall']) \n",
    "    ax[0, 1].plot(history.history['val_recall'])\n",
    "    ax[0, 1].set_title('Model recall', fontsize = 18)\n",
    "    ax[0, 1].set_ylabel('Recall', fontsize = 14) \n",
    "    ax[0, 1].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[0, 1].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[0, 1].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "    # --- PRECISION\n",
    "    ax[1, 0].plot(history.history['precision'])\n",
    "    ax[1, 0].plot(history.history['val_precision'])\n",
    "    ax[1, 0].set_title('Model precision', fontsize = 18)\n",
    "    ax[1, 0].set_ylabel('Precision', fontsize = 14)\n",
    "    ax[1, 0].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[1, 0].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[1, 0].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "    # --- F1 SCORE \n",
    "    ax[1, 1].plot(history.history['f1_score'])\n",
    "    ax[1, 1].plot(history.history['val_f1_score']) \n",
    "    ax[1, 1].set_title('Model F1 Score', fontsize = 18)\n",
    "    ax[1, 1].set_ylabel('F1 Score', fontsize = 14)\n",
    "    ax[1, 1].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[1, 1].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[1, 1].grid(axis=\"y\", linewidth=0.5)\n",
    "    \n",
    "    # --- AUC\n",
    "    ax[2, 0].plot(history.history['auc'])\n",
    "    ax[2, 0].plot(history.history['val_auc'])\n",
    "    ax[2, 0].set_title('Model AUC', fontsize = 18) \n",
    "    ax[2, 0].set_ylabel('AUC', fontsize = 14)\n",
    "    ax[2, 0].legend(['Train', 'Val'], loc='lower right')\n",
    "    ax[2, 0].grid(axis=\"x\", linewidth=0.5)\n",
    "    ax[2, 0].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "\n",
    "#     ax[2, 1].plot(history.history['tp'])\n",
    "#     ax[2, 1].plot(history.history['val_tp'])\n",
    "#     ax[2, 1].set_title('Model True Positive', fontsize = 18) \n",
    "#     ax[2, 1].set_ylabel('TP', fontsize = 14)\n",
    "#     ax[2, 1].legend(['Train', 'Val'], loc='lower right')\n",
    "#     ax[2, 1].grid(axis=\"x\", linewidth=0.5)\n",
    "#     ax[2, 1].grid(axis=\"y\", linewidth=0.5)\n",
    "\n",
    "    # Set common labels  \n",
    "    fig.text(0.5, 0.04, 'Epoch', ha='center', va='center', fontsize=14) \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d80f160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/fabiosparano/code/janduplessis883/project-showupforhealth/wandb/run-20230909_174244-kfyikwa7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bromptonhealthpcn/ShowUp%20NEW%20DATA/runs/kfyikwa7' target=\"_blank\">logical-paper-32</a></strong> to <a href='https://wandb.ai/bromptonhealthpcn/ShowUp%20NEW%20DATA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bromptonhealthpcn/ShowUp%20NEW%20DATA' target=\"_blank\">https://wandb.ai/bromptonhealthpcn/ShowUp%20NEW%20DATA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bromptonhealthpcn/ShowUp%20NEW%20DATA/runs/kfyikwa7' target=\"_blank\">https://wandb.ai/bromptonhealthpcn/ShowUp%20NEW%20DATA/runs/kfyikwa7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bromptonhealthpcn/ShowUp%20NEW%20DATA/runs/kfyikwa7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x14974f6a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "# Start a run, tracking hyperparameters\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"ShowUp NEW DATA\",\n",
    "\n",
    "    # track hyperparameters and run metadata with wandb.config\n",
    "    config={\n",
    "        \"layer_1\": 64,\n",
    "        \"activation_1\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.3, 0.8),\n",
    "        \"layer_2\": 128,\n",
    "        \"activation_2\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.3, 0.8),\n",
    "        \"layer_3\": 80,\n",
    "        \"activation_3\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.3, 0.8),\n",
    "        \"layer_4\": 16,\n",
    "        \"activation_4\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.3, 0.8),\n",
    "        \"layer_5\": 64,\n",
    "        \"activation_5\": \"relu\",\n",
    "        \"dropout\": random.uniform(0.3, 0.8),\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"epoch\": 80,\n",
    "        \"batch_size\": 128\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e9ea975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T07:06:14.743121Z",
     "start_time": "2023-07-31T07:06:14.604175Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def init_model():\n",
    "\n",
    "    # Assuming X_train_o_s is globally accessible; otherwise, pass it as a parameter.\n",
    "    # Only take the dimensions of a single sample, excluding the batch size.\n",
    "    input_shape = X_train_scaled.shape[1:]\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Input layer specifying the shape\n",
    "    model.add(layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "#     model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=1e-4)\n",
    "    \n",
    "    # Assuming 'metrics' is defined globally; otherwise, specify it directly or pass it as a parameter.\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "042be68a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T07:06:17.931535Z",
     "start_time": "2023-07-31T07:06:16.838275Z"
    }
   },
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201ea69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T07:06:38.133672Z",
     "start_time": "2023-07-31T07:06:17.932703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/80\n",
      "INFO:tensorflow:Assets written to: models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/80\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(\n",
    "    patience=30,\n",
    "    monitor='val_recall', # We really want to detect fraudulent transactions!\n",
    "    restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train_o,\n",
    "                    validation_data=(X_val_scaled, y_val),\n",
    "                    epochs=80,\n",
    "                    batch_size=128, # Large enough to get a decent chance of containing fraudulent transactions \n",
    "                    callbacks=[es,\n",
    "                      WandbMetricsLogger(log_freq=5),\n",
    "                      WandbModelCheckpoint(\"models\")], \n",
    "                    shuffle=True,\n",
    "                    verbose=3\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18051cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T07:06:38.797653Z",
     "start_time": "2023-07-31T07:06:38.136164Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_precision_recall_curve(history)\n",
    "print(\"Show Up for Health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319072db",
   "metadata": {},
   "source": [
    "# Score model on unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ce418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:43:31.716520Z",
     "start_time": "2023-07-31T06:43:29.929511Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0e42c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:43:36.488663Z",
     "start_time": "2023-07-31T06:43:35.792344Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7da8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "datetime_string = now.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "model.save(f'model_weights_{datetime_string}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09994d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:43:54.615057Z",
     "start_time": "2023-07-31T06:43:53.912913Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576adafc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:02.554092Z",
     "start_time": "2023-07-31T06:44:02.464459Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.50 # 50% \n",
    "\n",
    "y_pred_binary = np.where(y_pred_proba > threshold, 1, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96876d",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786ff08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:06.263268Z",
     "start_time": "2023-07-31T06:44:06.160737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test,y_pred_binary)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebe0c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:08.332607Z",
     "start_time": "2023-07-31T06:44:08.137717Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d8189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:33.862657Z",
     "start_time": "2023-07-31T06:44:33.712813Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d1b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:35.437489Z",
     "start_time": "2023-07-31T06:44:35.356271Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = precision_recall_curve(labels, predictions)\n",
    "    plt.plot(recall, precision, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c01fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T06:44:36.687973Z",
     "start_time": "2023-07-31T06:44:36.527403Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_prc(\"Test\", y_test, y_pred_proba, linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50b547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17f082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
